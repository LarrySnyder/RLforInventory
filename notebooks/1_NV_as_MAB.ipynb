{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1: NV as MAB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPe1+wZdbKckpn/CcuZygd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LarrySnyder/RLforInventory/blob/main/notebooks/1_NV_as_MAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Newsvendor Problem as a Multi-Armed Bandit (MAB)\n",
        "\n",
        "This notebook contains code for an MAB implementation of the newsvendor problem.\n",
        "\n",
        "---\n",
        "> **Note:** This file is read-only. To work with it, you first need to save a copy to your Google Drive:\n",
        "> \n",
        "> 1. Go to the File menu. (The File menu inside the notebook, right below the filenameâ€”not the File menu in your browser, at the top of your screen.)\n",
        "> 2. Choose Save a copy in Drive. (Log in to your Google account, if necessary.) Feel free to move it to a different folder in your Drive, if you want.\n",
        "> 3. Colab should open up a new browser tab with your copy of the notebook. \n",
        "> 4. Close the original read-only notebook in your browser.\n",
        "---\n",
        "\n",
        "---\n",
        "> This notebook is part of the *Summer Bootcamp at Kellogg: RL in Operations* workshop at Northwestern University, August 2022. The notebooks are for Day 4, taught by Prof. Larry Snyder, Lehigh University.\n",
        "---"
      ],
      "metadata": {
        "id": "Ulij2zKcmrrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [INTRO MAB/NV STUFF HERE]"
      ],
      "metadata": {
        "id": "lJy8OExCbHMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preliminary Python Stuff"
      ],
      "metadata": {
        "id": "Uf0iIJL1bM4o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LtETQocUlivA"
      },
      "outputs": [],
      "source": [
        "# Import the packages we will need.\n",
        "import numpy as np\n",
        "#import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm, poisson\n",
        "#from tqdm.notebook import tqdm\n",
        "#from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to install the `stockpyl` package so we can use it below. (It doesn't come pre-installed on Colab like `numpy`, etc. do.) You should only need to do this once per notebook.\n",
        "\n",
        "If you get a message like\n",
        "\n",
        "```\n",
        "WARNING: The following packages were previously imported in this runtime:\n",
        "  [sphinxcontrib]\n",
        "You must restart the runtime in order to use newly installed versions.\n",
        "```\n",
        "\n",
        "you can ignore it.\n"
      ],
      "metadata": {
        "id": "mvYa1KQUnuVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stockpyl"
      ],
      "metadata": {
        "id": "0-KOixlOny1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stockpyl import newsvendor"
      ],
      "metadata": {
        "id": "tQq454GKoC7d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bandit Class\n",
        "\n",
        "First, we'll define a `Bandit` class that implements a multi-armed bandit (MAB). \n",
        "\n",
        "The class is very simple. It has two attributes:\n",
        "\n",
        "* `k`: the number of arms\n",
        "* `mean`: a list of mean rewards, one per bandit\n",
        "* `sd`: a list of standard deviations of rewards, one per bandit\n",
        "\n",
        "And the class has three methods:\n",
        "\n",
        "* `__init__()` initializes the class\n",
        "* `optimal_action()` returns the index of the optimal action; this is basically just a shortcut to the optimal solution\n",
        "* `pull()` takes an action and returns a randomly generated reward for that action\n",
        "\n",
        "At its default values, the bandit has $k=5$ arms whose rewards have mean $[1, \\ldots, 5]$ (respectively) and standard deviation 1."
      ],
      "metadata": {
        "id": "SslqScfqbukw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Bandit(object):\n",
        "\n",
        "    def __init__(self, k: int = 5, mean: list = list(range(5)), sd: list = [1]*5):\n",
        "        \"\"\"Initialize the attributes.\"\"\"\n",
        "        self.k = k\n",
        "        self.mean = mean\n",
        "        self.sd = sd\n",
        "\n",
        "    def optimal_action(self):\n",
        "        \"\"\"Return the action with the largest mean.\"\"\"\n",
        "        return np.argmax(self.mean)\n",
        "\n",
        "    def pull(self, action: int):\n",
        "        \"\"\"Get a random variate from a normal distribution with the mean and SD\n",
        "        corresponding to the action.\"\"\"\n",
        "        return norm.rvs(loc=self.mean[action], scale=self.sd[action])\n"
      ],
      "metadata": {
        "id": "436FfGBHdXqd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's give it a spin ðŸŽ°. \n",
        "\n",
        "(Sorryâ€”dad joke.) "
      ],
      "metadata": {
        "id": "zBFNKQJ-eFsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bandit = Bandit(k=3, mean=[5, 3, 1], sd=[1, 1, 0.5])\n",
        "for _ in range(10):\n",
        "    a = np.random.randint(3)\n",
        "    r = bandit.pull(a)\n",
        "    print(f\"Pulled arm {a}, got reward {r}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-0IjixGePss",
        "outputId": "ddf7952a-3ee2-43d6-ff8a-ea01d1560f93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pulled arm 1, got reward 2.6505163634537108\n",
            "Pulled arm 2, got reward 1.146996844526327\n",
            "Pulled arm 0, got reward 4.470522700587773\n",
            "Pulled arm 2, got reward 1.5056028339566427\n",
            "Pulled arm 0, got reward 6.192360347129539\n",
            "Pulled arm 0, got reward 5.544880126515056\n",
            "Pulled arm 2, got reward 1.4695600171647771\n",
            "Pulled arm 0, got reward 6.17350656578218\n",
            "Pulled arm 0, got reward 3.753395532819381\n",
            "Pulled arm 1, got reward 3.215182831297481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\epsilon$-Greedy Class\n",
        "\n",
        "Next we'll define an `EpsilonGreedyAgent` class that implements the $\\epsilon$-greedy algorithm for generic MABs. The algorithm implementation is based on the discussions in Sutton and Barto (2nd edition, 2018).\n",
        "\n",
        "In order to use the class, you need to provide it with an instance of the `Bandit` class defined above.\n",
        "\n",
        "Feel free to explore the code if you want, but all that's required is for you to execute the cell."
      ],
      "metadata": {
        "id": "totid_CXbVgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EpsilonGreedyAgent(object):\n",
        "\n",
        "    def __init__(self, bandit: Bandit, epsilon: float = 0.1):\n",
        "        # Initialize the attributes.\n",
        "        self.bandit = bandit\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def epsilon_greedy(self, num_time_steps: int = 1000, initial_Q: list = None):\n",
        "        # Initialize Q-value estimates (or use `initial_Q` if provided).\n",
        "        Q = initial_Q or [0] * self.bandit.k\n",
        "        # Initialize action counts.\n",
        "        N = [0] * self.bandit.k\n",
        "\n",
        "        # Initialize evaluation info.\n",
        "        \n",
        "        # Main loop.\n",
        "        for t in range(num_time_steps):\n",
        "\n",
        "            # Choose action.\n",
        "            if np.random.rand() < 1 - self.epsilon:\n",
        "                A = np.argmax(Q)\n",
        "            else:\n",
        "                A = np.random.randint(self.bandit.k)\n",
        "\n",
        "            # Get reward.\n",
        "            R = self.bandit.pull(A)\n",
        "\n",
        "            # Update stats.\n",
        "            N[A] += 1\n",
        "            Q[A] += (1 / N[A]) * (R - Q[A])\n",
        "\n",
        "        # Return Q estimates as well as best guess for optimal action.\n",
        "        return Q, np.argmax(Q)"
      ],
      "metadata": {
        "id": "FmUJRaMVbRtx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try it."
      ],
      "metadata": {
        "id": "kGibmGgOhVQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = EpsilonGreedyAgent(bandit)\n",
        "Q, A = agent.epsilon_greedy()\n",
        "print(f\"Best guess for optimal action is {A}\")\n",
        "print(f\"Estimates of action values:\")\n",
        "for a in range(bandit.k):\n",
        "    print(f\"  {a}: {Q[a]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMI4FlKHhTPQ",
        "outputId": "065304bc-9299-4f3c-ebdc-156a4fcbfff2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best guess for optimal action is 0\n",
            "Estimates of action values:\n",
            "  0: 4.922213190810981\n",
            "  1: 2.993602234912368\n",
            "  2: 0.9172141877282236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Newsvendor Bandit\n",
        "\n",
        "Now it's your turn. Your goal is to build a class called `NewsvendorBandit`. I started you off by building the structure of the class. (It's similar to the `Bandit` class declared earlier.) You need to fill in some details.\n",
        "\n",
        "A few things to note:\n",
        "\n",
        "* The `NewsvendorBandit` class takes a parameter `k`, like the `Bandit` class, that indicates the number of \"arms\". The arms will be indexed $a=0,\\ldots,k-1$, and arm $a$ corresponds to using an order quantity of $a$.\n",
        "* The class takes three parameters specifying the newsvendor problem instance: \n",
        "\n",
        "    * `h` and `p` are the holding and stockout costs\n",
        "    * `mu` is the mean of the Poisson demand distribution\n",
        "    \n",
        "* \"Pulling\" an arm should return the **negative of the cost of one newsvendor period,** based on a randomly generated demand, rather than returning a random variate from a particular distribution.\n",
        "\n",
        "---\n",
        "**Note:** In the code below, the portions that you need to complete are marked with\n",
        "\n",
        "```python\n",
        "# #################\n",
        "# TODO:\n",
        "```\n",
        "\n",
        "In place of the missing code is a line that says \n",
        "\n",
        "```python\n",
        "\traise NotImplementedError\n",
        "```\n",
        "\n",
        "This is a way of telling Python to raise an exception (error) because there's something missing here. You should **delete (or comment out) this line** after you write your code.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "xqpmsNTGiS5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsvendorBandit(object):\n",
        "\n",
        "    def __init__(self, k: int = 10, h: float = 1, p: float = 10, mu: int = 5):\n",
        "        \"\"\"Initialize the attributes.\"\"\"\n",
        "        self.k = k\n",
        "\n",
        "        # #################\n",
        "        # TODO: store the attributes h, p, and mu in the object, too.\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def optimal_action(self):\n",
        "        \"\"\"Return the action with the smallest expected cost.\"\"\"\n",
        "        # #################\n",
        "        # TODO: Set `action` to the action that minimizes the expected cost.\n",
        "        # Hint: use stockpyl's newsvendor_poisson() function. \n",
        "        # See https://stockpyl.readthedocs.io/en/latest/api/seio/newsvendor.html#stockpyl.newsvendor.newsvendor_poisson\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return action\n",
        "\n",
        "    def pull(self, action: int):\n",
        "        \"\"\"Return a random newsvendor cost for the given action.\"\"\"\n",
        "\n",
        "        # Generate a Poisson(mu) random variate.\n",
        "        d = poisson.rvs(self.mu)\n",
        "\n",
        "        # #################\n",
        "        # TODO: Calculate the cost for the chosen action and the random demand.\n",
        "        # Set `reward` to the negative of this cost.\n",
        "        raise NotImplementedError\n",
        "\n",
        "        # Get a random variate from a normal distribution with the mean and SD\n",
        "        # corresponding to the action.\n",
        "        return reward"
      ],
      "metadata": {
        "id": "o3KQ7tiDj5Mj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SOLUTION ##\n",
        "class NewsvendorBandit(object):\n",
        "\n",
        "    def __init__(self, k: int = 10, h: float = 1, p: float = 10, mu: int = 5):\n",
        "        \"\"\"Initialize the attributes.\"\"\"\n",
        "        self.k = k\n",
        "\n",
        "        # Store the attributes h, p, and mu in the object, too.\n",
        "        self.h = h\n",
        "        self.p = p\n",
        "        self.mu = mu\n",
        "\n",
        "    def optimal_action(self):\n",
        "        \"\"\"Return the action with the smallest expected cost.\"\"\"\n",
        "        # Set `action` to the action that minimizes the expected cost,\n",
        "        # using stockpyl's newsvendor_poisson() function. \n",
        "        action, _ = newsvendor.newsvendor_poisson(self.h, self.p, self.mu)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def pull(self, action: int):\n",
        "        \"\"\"Return a random newsvendor cost for the given action.\"\"\"\n",
        "\n",
        "        # Generate a Poisson(mu) random variate.\n",
        "        d = poisson.rvs(self.mu)\n",
        "\n",
        "        # Calculate the cost for the chosen action and the random demand.\n",
        "        # Set `reward` to the negative of this cost.\n",
        "        cost = self.h * max(action - d, 0) + self.p * max(d - action, 0)\n",
        "        reward = -cost\n",
        "\n",
        "        # Get a random variate from a normal distribution with the mean and SD\n",
        "        # corresponding to the action.\n",
        "        return reward"
      ],
      "metadata": {
        "id": "UyaPN8PGnBhx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try out your `NewsvendorBandit` class on a newsvendor instance with:\n",
        "\n",
        "* $h=0.5$\n",
        "* $p=15$\n",
        "* $\\mu=4$\n",
        "\n",
        "We'll use 12 arms."
      ],
      "metadata": {
        "id": "iWGvFHxmpL7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the bandit.\n",
        "num_arms = 12\n",
        "bandit = NewsvendorBandit(k=num_arms, h=0.5, p=15, mu=4)"
      ],
      "metadata": {
        "id": "Ge8dh2PAsoXa"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull lever 5 a few times.\n",
        "a = 5\n",
        "for _ in range(10):\n",
        "    r = bandit.pull(a)\n",
        "    print(f\"Pulled arm {a}, got reward {r}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5yLPe5rsqjc",
        "outputId": "ab077e87-1811-409e-ad29-e14781b80f94"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pulled arm 5, got reward -1.0\n",
            "Pulled arm 5, got reward -1.0\n",
            "Pulled arm 5, got reward -0.0\n",
            "Pulled arm 5, got reward -0.5\n",
            "Pulled arm 5, got reward -1.0\n",
            "Pulled arm 5, got reward -2.5\n",
            "Pulled arm 5, got reward -0.0\n",
            "Pulled arm 5, got reward -15.0\n",
            "Pulled arm 5, got reward -0.5\n",
            "Pulled arm 5, got reward -30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull it a lot of times and get the average reward.\n",
        "avg_reward = 0\n",
        "a = 5\n",
        "num_pulls = 10000\n",
        "for _ in range(num_pulls):\n",
        "    r = bandit.pull(a)\n",
        "    avg_reward += r / num_pulls\n",
        "print(f\"Pulled arm {a} {num_pulls} times, got average reward {avg_reward}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8IlvDjppE-3",
        "outputId": "adc6ba15-2b14-4048-a6a0-d7f41bcc1c1b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pulled arm 5 10000 times, got average reward -7.126349999999884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the *exact* optimal action, according to the bandit?\n",
        "opt_action = bandit.optimal_action()\n",
        "print(f\"Optimal action is {opt_action}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B5SWgmlstu5",
        "outputId": "9758cb1e-6cf5-441d-92a4-597d7b5051a7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal action is 8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's validate this by calculating the expected cost of using an order quantity of 5 (`stockpyl` calls this `base_stock_level`) for the given newsvendor instance."
      ],
      "metadata": {
        "id": "aR6s9gufqaRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, exp_cost = newsvendor.newsvendor_poisson(\n",
        "    bandit.h,\n",
        "    bandit.p,\n",
        "    bandit.mu,\n",
        "    base_stock_level=a\n",
        ")\n",
        "print(f\"Exact expected cost for order quantity 5 is {exp_cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPs7W_bup1zW",
        "outputId": "63ad07aa-916e-4281-8772-d9b1ceab5442"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact expected cost for order quantity 5 is 6.859715013704245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's get the *optimal* order quantity using `stockpyl`."
      ],
      "metadata": {
        "id": "XjX6zNg-tM0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt_Q, opt_exp_cost = newsvendor.newsvendor_poisson(\n",
        "    bandit.h,\n",
        "    bandit.k,\n",
        "    bandit.mu\n",
        ")\n",
        "print(f\"Optimal order quantity is {opt_Q}, with expected cost {opt_exp_cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KgwktR5tKSu",
        "outputId": "a089cb12-5b94-4f73-d295-3985d958e6cd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal order quantity is 8.0, with expected cost 2.4203373408439486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Note:** Before proceeding, you should make sure that the results from your bandit are similar to those returned by `stockpyl`.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KT-s9Y0Etfs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the $\\epsilon$-Greedy Agent for the Newsvendor MAB\n",
        "\n",
        "Now let's train the $\\epsilon$-greedy agent on the newsvendor MAB. The `EpsilonGreedyAgent` class does not need any modificationsâ€”we built it to be very genericâ€”so all you need to do is pass your newsvendor bandit to it."
      ],
      "metadata": {
        "id": "ZJ9vRzGsrhBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #################\n",
        "# TODO: Train the epsilon-greedy agent on your `NewsvendorBandit` object.\n",
        "# Print the agent's buess guess for the optimal action, as well as its\n",
        "# estimates of the action values. (Use the analogous cell above as a template.)\n",
        "raise NotImplementedError"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jeCiauAFq9r8",
        "outputId": "41c398c9-2244-43fe-f5fe-c42fa58361e5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-51308e584b42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Print the agent's buess guess for the optimal action, as well as its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# estimates of the action values. (Use the analogous cell above as a template.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## SOLUTION\n",
        "agent = EpsilonGreedyAgent(bandit)\n",
        "Q, A = agent.epsilon_greedy(num_time_steps=1000)\n",
        "print(f\"Best guess for optimal action is {A}\")\n",
        "print(f\"Estimates of action values:\")\n",
        "for a in range(bandit.k):\n",
        "    print(f\"  {a}: {Q[a]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vgfizqauU8_",
        "outputId": "886a526a-8538-4169-8244-69de3d0ffe38"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best guess for optimal action is 8\n",
            "Estimates of action values:\n",
            "  0: -60.0\n",
            "  1: -50.0\n",
            "  2: -27.583333333333336\n",
            "  3: -7.5\n",
            "  4: -15.392857142857142\n",
            "  5: -7.6\n",
            "  6: -3.3636363636363638\n",
            "  7: -3.9351851851851847\n",
            "  8: -2.33434835566382\n",
            "  9: -2.4285714285714284\n",
            "  10: -2.8181818181818183\n",
            "  11: -3.1875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validating the Results\n",
        "\n",
        "Let's compare your trained agent's action-value estimates (or really, their negatives) with the true expected costs of those actions as calculated by `stockpyl`. \n",
        "\n",
        "(The code below assumes that you have stored the agent's estimates of the action values in a variable called `Q` in the previous cell.)"
      ],
      "metadata": {
        "id": "tBkBYNwTuhGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "action_list = list(range(bandit.k))\n",
        "\n",
        "bandit_cost = [-Q[a] for a in action_list]\n",
        "exp_cost = [newsvendor.newsvendor_poisson(\n",
        "    bandit.h, \n",
        "    bandit.p, \n",
        "    bandit.mu, \n",
        "    base_stock_level=a\n",
        ")[1] for a in action_list]\n",
        "\n",
        "plt.scatter(action_list, bandit_cost, label='Bandit Cost Estimates')\n",
        "plt.scatter(action_list, exp_cost, label='True Expected Cost')\n",
        "plt.legend()\n",
        "plt.xlabel('Action')\n",
        "plt.ylabel('Cost');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "noxioRjzuaS2",
        "outputId": "48386500-a087-476b-d7a7-c920e853f426"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How good a job did your bandit and $\\epsilon$-greedy agent do of estimating the expected cost function for the newsvendor problem?\n",
        "\n",
        "(If you're not happy with the results, you can try increasing the `num_time_steps` parameter passed to the `epsilon_greedy()` method.)"
      ],
      "metadata": {
        "id": "cy5Wrkekw-BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gOePid0svdqw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}